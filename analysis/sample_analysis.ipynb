{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import language.decoder\n",
    "\n",
    "import yaml\n",
    "from keras import  models\n",
    "\n",
    "from datasets.googlecc import PreProcessing\n",
    "from datasets.common import get_dataset_metadata_cfg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../configs/inception_lstm_preprocessed1.yaml\") as fp:\n",
    "    cfg = yaml.load(fp)\n",
    "\n",
    "model_workspace_dir = os.path.join(cfg[\"workspace\"][\"directory\"], cfg[\"dataset\"][\"name\"], cfg[\"model\"][\"arch\"])\n",
    "\n",
    "dataset_cfg = get_dataset_metadata_cfg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_preprocessor = PreProcessing(cfg, \"inception\", False, False)\n",
    "training_generator, validation_generator, test_generator = dataset_preprocessor.get_keras_generators(\"inception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = models.load_model(os.path.join(model_workspace_dir, 'weights.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fp = open(dataset_cfg[\"data\"][\"googlecc\"][\"test_images_file\"])\n",
    "\n",
    "lines = fp.readlines()\n",
    "number_test_examples = 100\n",
    "generated_sentences = []\n",
    "images = []\n",
    "for i in range(number_test_examples):\n",
    "    img = mpimg.imread(\n",
    "        os.path.join(dataset_cfg[\"data\"][\"googlecc\"][\"dataset_path\"],lines[i].strip())\n",
    "    )\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n",
    "    x, y = test_generator[i]\n",
    "    sentence = language.decoder.greedy_decoder(\n",
    "        model,\n",
    "        x[0][0],\n",
    "        dataset_preprocessor.get_word_dictionary(),\n",
    "        dataset_preprocessor.get_id_dictionary(),\n",
    "        40)\n",
    "    generated_sentences.append(sentence)\n",
    "    images.append(lines[i].strip())\n",
    "\n",
    "data = {'Image ID': images, 'Model Output': generated_sentences }\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLEU analysis\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "dataset_workspace_dir = os.path.join(cfg[\"workspace\"][\"directory\"], cfg[\"dataset\"][\"name\"])\n",
    "with open(os.path.join(dataset_workspace_dir, 'google_cc_processed_descriptions.txt')) as f:\n",
    "    data = f.read()\n",
    "\n",
    "img_captions = dict()\n",
    "for line in data.split(\"\\n\"):\n",
    "    if line.strip():\n",
    "        tokens = line.split()\n",
    "        image_id , image_desc = tokens[0],tokens[1:]\n",
    "        img_captions[image_id] = image_desc\n",
    "\n",
    "\n",
    "bleu_scores = []\n",
    "score_sum = 0\n",
    "for i in range(number_test_examples):\n",
    "    image = df['Image ID'].iloc[i]\n",
    "    candidate = df['Model Output'].iloc[i]\n",
    "    candidate = candidate[1:-1]\n",
    "    references = []\n",
    "    references.append(img_captions[image.strip()])\n",
    "    bleu_score = sentence_bleu(references, candidate, weights=(1, 0, 0, 0))\n",
    "    bleu_scores.append(bleu_score)\n",
    "    score_sum += bleu_score\n",
    "\n",
    "df['Bleu Score'] = bleu_scores\n",
    "df.to_csv(os.path.join(model_workspace_dir, \"bleu_scores.csv\"))\n",
    "\n",
    "average_bleu = score_sum/number_test_examples\n",
    "print(\"Average BLEU score\", average_bleu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
